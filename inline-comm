import os
import subprocess
import requests
import json
import re
import ssl
import urllib3
from typing import List, Dict, Optional
from dataclasses import dataclass

# Disable SSL warnings and verification for testing
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

@dataclass
class CodeIssue:
    file_path: str
    line_number: int
    severity: str
    message: str
    rule: str

class CodeAnalyzer:
    def __init__(self):
        self.rules = {
            'missing_docstring': {
                'pattern': r'^def\s+\w+\([^)]*\):\s*$',
                'message': 'Consider adding a docstring to document this function.',
                'severity': 'suggestion'
            },
            'hardcoded_strings': {
                'pattern': r'print\([\'"][^\'\"]*[\'\"]\)',
                'message': 'Consider using constants for hardcoded strings.',
                'severity': 'suggestion'
            },
            'long_lines': {
                'check_length': True,
                'max_length': 100,
                'message': 'Line is too long. Consider breaking it up for readability.',
                'severity': 'suggestion'
            }
        }
    
    def analyze_file_content(self, file_path: str, content: str, diff_lines: List[int]) -> List[CodeIssue]:
        issues = []
        lines = content.split('\n')
        
        for line_num in diff_lines:
            if line_num <= 0 or line_num > len(lines):
                continue
                
            line = lines[line_num - 1]
            line_stripped = line.strip()
            
            # Check each rule
            for rule_name, rule_config in self.rules.items():
                issue = self._check_rule(file_path, line_num, line, line_stripped, rule_name, rule_config)
                if issue:
                    issues.append(issue)
        
        return issues
    
    def _check_rule(self, file_path: str, line_num: int, line: str, line_stripped: str, rule_name: str, config: Dict) -> Optional[CodeIssue]:
        # Check line length rule
        if rule_name == 'long_lines' and config.get('check_length'):
            if len(line) > config['max_length']:
                return CodeIssue(
                    file_path=file_path,
                    line_number=line_num,
                    severity=config['severity'],
                    message=config['message'],
                    rule=rule_name
                )
        
        # Check pattern-based rules
        elif 'pattern' in config:
            if re.search(config['pattern'], line_stripped):
                return CodeIssue(
                    file_path=file_path,
                    line_number=line_num,
                    severity=config['severity'],
                    message=config['message'],
                    rule=rule_name
                )
        
        return None

class DiffExtractor:
    @staticmethod
    def extract_pr_changes(base_branch: str = "origin/main") -> Dict[str, Dict]:
        script_files_to_exclude = ['inline-comm.py', 'extract_pr_diffs.py']
        
        # Build exclude patterns
        exclude_patterns = [f":(exclude){f}" for f in script_files_to_exclude]
        
        diff_cmd = [
            "git", "diff", f"{base_branch}...HEAD", 
            "--", "*.py"
        ] + exclude_patterns
        
        try:
            result = subprocess.run(diff_cmd, capture_output=True, text=True, check=True)
            diff_output = result.stdout.strip()
        except subprocess.CalledProcessError as e:
            print(f"Git diff failed: {e}")
            return {}
        
        if not diff_output:
            print("No diff output found")
            return {}
            
        return DiffExtractor._parse_diff_output(diff_output, script_files_to_exclude)
    
    @staticmethod
    def _parse_diff_output(diff_output: str, exclude_files: List[str]) -> Dict[str, Dict]:
        files = {}
        current_file = None
        current_line_number = 0
        
        for line in diff_output.splitlines():
            if line.startswith("diff --git"):
                # Extract filename
                parts = line.split()
                if len(parts) >= 4 and parts[3].startswith("b/"):
                    current_file = parts[3][2:]
                    
                    # Skip excluded files
                    if current_file in exclude_files:
                        current_file = None
                        continue
                    
                    files[current_file] = {
                        'changed_lines': [],
                        'content': None
                    }
                    
            elif line.startswith("@@") and current_file:
                # Parse hunk header to get line numbers
                # Format: @@ -old_start,old_count +new_start,new_count @@
                match = re.search(r'\+(\d+),?(\d+)?', line)
                if match:
                    start_line = int(match.group(1))
                    count = int(match.group(2)) if match.group(2) else 1
                    current_line_number = start_line
                    
            elif line.startswith("+") and not line.startswith("+++") and current_file:
                # This is an added line
                files[current_file]['changed_lines'].append(current_line_number)
                current_line_number += 1
                
            elif not line.startswith("-") and current_file and current_line_number > 0:
                # Context line or unchanged line
                current_line_number += 1
        
        # Get current file contents
        for file_path in list(files.keys()):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    files[file_path]['content'] = f.read()
                    
                # If no changed lines detected, analyze first few lines as fallback
                if not files[file_path]['changed_lines']:
                    files[file_path]['changed_lines'] = [1, 2, 3, 4, 5]
                    
            except FileNotFoundError:
                print(f"Warning: File {file_path} not found locally")
                del files[file_path]
        
        return files

class GitHubCommenter:
    def __init__(self, token: str, repo_owner: str, repo_name: str):
        self.token = token
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        
        # Create session with SSL verification disabled
        self.session = requests.Session()
        self.session.verify = False
        
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json'
        }
        self.base_url = f'https://api.github.com/repos/{repo_owner}/{repo_name}'
    
    def post_review_comments(self, pr_number: int, issues: List[CodeIssue]) -> Dict:
        if not issues:
            print("No issues found to comment on.")
            return {"posted": 0, "errors": 0}
        
        # Get PR info to get the commit SHA
        try:
            pr_response = self.session.get(f'{self.base_url}/pulls/{pr_number}', headers=self.headers)
            pr_response.raise_for_status()
            commit_sha = pr_response.json()['head']['sha']
            print(f"Got PR info. Commit SHA: {commit_sha}")
        except Exception as e:
            print(f"Failed to get PR info: {e}")
            return {"posted": 0, "errors": len(issues)}
        
        posted_count = 0
        error_count = 0
        
        print(f"Posting {len(issues)} code review comments...")
        
        for i, issue in enumerate(issues, 1):
            try:
                print(f"[{i}/{len(issues)}] Posting comment on {issue.file_path}:{issue.line_number}")
                
                payload = {
                    'body': f"**{issue.severity.upper()}**: {issue.message}",
                    'commit_id': commit_sha,
                    'path': issue.file_path,
                    'line': issue.line_number
                }
                
                response = self.session.post(
                    f'{self.base_url}/pulls/{pr_number}/comments',
                    headers=self.headers,
                    json=payload
                )
                
                if response.status_code == 201:
                    print(f"  âœ“ Success!")
                    posted_count += 1
                else:
                    print(f"  âœ— Failed: {response.status_code}")
                    print(f"    Response: {response.text}")
                    error_count += 1
                    
            except Exception as e:
                print(f"  âœ— Error: {e}")
                error_count += 1
        
        # Post summary review
        self._post_summary_review(pr_number, issues, posted_count, error_count)
        
        return {"posted": posted_count, "errors": error_count}
    
    def _post_summary_review(self, pr_number: int, issues: List[CodeIssue], posted: int, errors: int):
        summary = f"""## Automated Code Review Summary

**Comments Posted**: {posted} / {len(issues)}

### Issues Found:
"""
        
        files_reviewed = list(set(issue.file_path for issue in issues))
        for file_path in files_reviewed:
            file_issues = [i for i in issues if i.file_path == file_path]
            summary += f"- `{file_path}`: {len(file_issues)} issues\n"
        
        summary += "\n*Generated by automated code review pipeline*"
        
        payload = {
            'body': summary,
            'event': 'COMMENT'
        }
        
        try:
            response = self.session.post(f'{self.base_url}/pulls/{pr_number}/reviews', 
                                       headers=self.headers, json=payload)
            if response.status_code == 200:
                print("âœ“ Posted summary review")
            else:
                print(f"âœ— Failed to post summary: {response.status_code}")
        except Exception as e:
            print(f"âœ— Failed to post summary: {e}")

def main():
    config = {
        'github_token': os.getenv('GITHUB_TOKEN'),
        'repo_owner': 'manishaitrivedi-dot',
        'repo_name': 'pr-diff-demo1',
        'pr_number': 3,
        'base_branch': 'origin/main'
    }
    
    if not config['github_token']:
        print("Error: GITHUB_TOKEN environment variable required")
        print("Set it with: set GITHUB_TOKEN=your_token_here")
        return
    
    print("Starting FULLY AUTOMATED PR code review pipeline...")
    print(f"Target: PR #{config['pr_number']} in {config['repo_owner']}/{config['repo_name']}")
    
    # Step 1: Extract changes from PR automatically
    print("\n1. Automatically extracting PR changes...")
    diff_extractor = DiffExtractor()
    file_changes = diff_extractor.extract_pr_changes(config['base_branch'])
    
    if not file_changes:
        print("No Python file changes found (excluding script files).")
        return
    
    print(f"Found changes in {len(file_changes)} files:")
    for file_path, data in file_changes.items():
        print(f"  - {file_path}: {len(data['changed_lines'])} lines to analyze")
    
    # Step 2: Analyze code and generate issues automatically
    print("\n2. Analyzing code for issues...")
    analyzer = CodeAnalyzer()
    all_issues = []
    
    for file_path, file_data in file_changes.items():
        if file_data['content'] and file_data['changed_lines']:
            issues = analyzer.analyze_file_content(
                file_path, 
                file_data['content'], 
                file_data['changed_lines']
            )
            all_issues.extend(issues)
            print(f"  - {file_path}: {len(issues)} issues found")
    
    if not all_issues:
        print("No issues found in the changed code.")
        return
    
    print(f"\nTotal issues found: {len(all_issues)}")
    
    # Step 3: Post comments to GitHub automatically
    print("\n3. Posting comments to GitHub...")
    commenter = GitHubCommenter(
        config['github_token'],
        config['repo_owner'],
        config['repo_name']
    )
    
    results = commenter.post_review_comments(config['pr_number'], all_issues)
    
    print(f"\nğŸ‰ Fully automated pipeline completed!")
    print(f"âœ“ Posted: {results['posted']} comments")
    print(f"âœ— Errors: {results['errors']} comments")
    
    if results['posted'] > 0:
        print(f"\nğŸ“ Check your PR for inline comments:")
        print(f"https://github.com/{config['repo_owner']}/{config['repo_name']}/pull/{config['pr_number']}")
        print("Click 'Files changed' tab to see the inline comments!")

if __name__ == "__main__":
    main()
