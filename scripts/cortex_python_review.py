#!/usr/bin/env python3
"""
Compatible inline comment script for executive code reviews
Works with both standard and executive review output formats
"""

import json
import os
import sys
from pathlib import Path

def load_review_data():
    """Load review data from available JSON files"""
    
    # Try multiple file locations for compatibility
    possible_files = [
        "review_output.json",
        "executive_review_output.json", 
        "dbt_code_review_output.json"
    ]
    
    for filename in possible_files:
        if os.path.exists(filename):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                print(f"âœ… Loaded review data from {filename}")
                return data, filename
            except json.JSONDecodeError as e:
                print(f"âŒ Error parsing {filename}: {e}")
                continue
            except Exception as e:
                print(f"âŒ Error reading {filename}: {e}")
                continue
    
    return None, None

def extract_critical_comments(review_data):
    """Extract critical findings that need inline comments"""
    
    criticals = review_data.get("criticals", [])
    detailed_findings = review_data.get("full_review_json", {}).get("detailed_findings", [])
    
    inline_comments = []
    
    # Process critical findings
    for critical in criticals:
        line_num = critical.get("line", 1)
        issue = critical.get("issue", "")
        recommendation = critical.get("recommendation", "")
        severity = critical.get("severity", "CRITICAL")
        
        comment_body = f"""ðŸš¨ **{severity} Issue**

**Issue:** {issue}

**Recommendation:** {recommendation}

**Business Impact:** {critical.get('business_impact', 'High priority fix required')}

---
*Generated by Executive Code Review System*"""
        
        inline_comments.append({
            "line": line_num,
            "body": comment_body,
            "severity": severity
        })
    
    # Also process high-severity findings from detailed analysis
    for finding in detailed_findings:
        if finding.get("severity", "").upper() in ["CRITICAL", "HIGH"]:
            line_num = finding.get("line_number", "1")
            if line_num.isdigit():
                line_num = int(line_num)
            else:
                continue
                
            severity = finding.get("severity", "HIGH")
            category = finding.get("category", "General")
            issue = finding.get("finding", "Issue detected")
            recommendation = finding.get("recommendation", "Review and fix")
            business_impact = finding.get("business_impact", "Potential impact on operations")
            
            # Skip if already added as critical
            if any(c["line"] == line_num for c in inline_comments):
                continue
            
            emoji = "ðŸš¨" if severity == "CRITICAL" else "âš ï¸"
            comment_body = f"""{emoji} **{severity} - {category}**

**Finding:** {issue}

**Recommendation:** {recommendation}

**Business Impact:** {business_impact}

**Effort Estimate:** {finding.get('effort_estimate', 'MEDIUM')}

---
*Generated by Executive Code Review System*"""
            
            inline_comments.append({
                "line": line_num,
                "body": comment_body,
                "severity": severity
            })
    
    return inline_comments

def generate_pr_comment_summary(review_data):
    """Generate the main PR comment summary"""
    
    full_review = review_data.get("full_review_markdown", review_data.get("full_review", ""))
    
    if not full_review:
        # Fallback summary generation
        executive_summary = review_data.get("executive_summary", {})
        quality_score = executive_summary.get("quality_score", "N/A")
        business_impact = executive_summary.get("business_impact", "MEDIUM")
        total_findings = executive_summary.get("total_findings", 0)
        critical_count = executive_summary.get("critical_count", 0)
        
        full_review = f"""# ðŸ“Š Executive Code Review Summary

**Quality Score:** {quality_score}/100 | **Business Risk:** {business_impact} | **Total Issues:** {total_findings}

## Key Findings
- ðŸ”´ **Critical Issues:** {critical_count}
- ðŸ“Š **Total Findings:** {total_findings}
- ðŸŽ¯ **Quality Score:** {quality_score}/100

## Executive Summary
{review_data.get('full_review_json', {}).get('executive_summary', 'Code analysis completed successfully.')}

---
*ðŸ”¬ Powered by Snowflake Cortex AI â€¢ Executive Technical Analysis*"""
    
    return full_review

def main():
    """Main execution function"""
    
    print("ðŸš€ Starting Inline Comment Processing...")
    print("="*60)
    
    # Load review data
    review_data, source_file = load_review_data()
    
    if not review_data:
        print("âŒ No review data found. Available options:")
        print("   1. Run cortex_python_review.py first")
        print("   2. Ensure review_output.json exists")
        print("   3. Check file permissions")
        sys.exit(1)
    
    print(f"ðŸ“‚ Using review data from: {source_file}")
    
    # Extract inline comments for critical/high issues
    inline_comments = extract_critical_comments(review_data)
    print(f"ðŸŽ¯ Found {len(inline_comments)} inline comments to generate")
    
    # Generate PR summary comment
    pr_summary = generate_pr_comment_summary(review_data)
    
    # Prepare output data
    output_data = {
        "pr_comment": pr_summary,
        "inline_comments": inline_comments,
        "summary": {
            "total_comments": len(inline_comments),
            "critical_count": len([c for c in inline_comments if c["severity"] == "CRITICAL"]),
            "high_count": len([c for c in inline_comments if c["severity"] == "HIGH"]),
            "source_file": source_file,
            "processed_at": review_data.get("timestamp", "unknown")
        }
    }
    
    # Save output
    with open("inline_comments_output.json", "w", encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    # Display results
    print("\n" + "="*60)
    print("âœ… INLINE COMMENT PROCESSING COMPLETED")
    print("="*60)
    print(f"ðŸ“Š Summary:")
    print(f"   â€¢ Total inline comments: {len(inline_comments)}")
    print(f"   â€¢ Critical issues: {len([c for c in inline_comments if c['severity'] == 'CRITICAL'])}")
    print(f"   â€¢ High priority issues: {len([c for c in inline_comments if c['severity'] == 'HIGH'])}")
    
    print(f"\nðŸ“ Generated Files:")
    print(f"   â€¢ inline_comments_output.json (GitHub integration ready)")
    
    print(f"\nðŸŽ¯ Next Steps:")
    print(f"   1. Use inline_comments_output.json for GitHub PR comments")
    print(f"   2. Apply inline comments to specific lines")
    print(f"   3. Post PR summary comment")
    
    if inline_comments:
        print(f"\nðŸ“‹ Preview of Inline Comments:")
        for i, comment in enumerate(inline_comments[:3], 1):
            print(f"   {i}. Line {comment['line']}: {comment['severity']} issue")
        if len(inline_comments) > 3:
            print(f"   ... and {len(inline_comments) - 3} more")
    
    print(f"\nâœ¨ Inline comment processing completed successfully!")

if __name__ == "__main__":
    main()
